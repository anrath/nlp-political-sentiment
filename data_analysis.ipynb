{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAffiliation(string):\n",
    "    affDict = {\n",
    "        'R': \n",
    "            [\n",
    "                'Trump',\n",
    "                'Dahle',\n",
    "                'Trimino',\n",
    "                'Cox',\n",
    "                'Lombardo',\n",
    "                'Laxalt',\n",
    "                'Lake',\n",
    "                'Ducey',\n",
    "                'Ronchetti',\n",
    "                'Pearce',\n",
    "                'Abbott',\n",
    "                'DeSantis'\n",
    "            ],\n",
    "        'D': \n",
    "            [\n",
    "                'Biden',\n",
    "                'Newsom',\n",
    "                'Sisolak',\n",
    "                'Hobbs',\n",
    "                'Grisham',\n",
    "                'Beto',\n",
    "                'Crist',\n",
    "                'Gillum',\n",
    "                'Valdez'\n",
    "            ]\n",
    "    }\n",
    "    \n",
    "    for key, entities in affDict.items():\n",
    "        for entity in entities:\n",
    "            if entity.lower() in str(string).lower():\n",
    "                return key\n",
    "    # print(f\"No affiliation found for {string}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './data'  # Replace with actual path\n",
    "all_data = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        affiliation = getAffiliation(filename)\n",
    "        df['Affiliation'] = affiliation\n",
    "        all_data.append(df)\n",
    "\n",
    "df = pd.concat(all_data, ignore_index=True)\n",
    "df = df.drop_duplicates(subset=['ad_creative_bodies']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv('data/ads_all.csv')\n",
    "# df2 = pd.read_csv('data/new_ads_all.csv')\n",
    "# df = pd.concat([df1, df2], ignore_index=True)\n",
    "# df = df.drop_duplicates(subset=['ad_creative_bodies'])\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_debate = pd.read_excel('kl/2020_pres_debate_translated.xlsx')\n",
    "df_debate['Affiliation'] = df_debate.apply(lambda x: getAffiliation(x['Speaker ']), axis=1)\n",
    "df_debate.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv of parties and rows are the names of candidates\n",
    "# compare the sentiment delta to below\n",
    "# ==============================================================================\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_debate = df_debate.rename(columns={\"Speaker \": \"Entity\", \"Verbatim\":\"English\", \"Spanish Translation \": \"Spanish\"})\n",
    "df_debate['languages'] = 'en'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"page_name\": \"Entity\"})\n",
    "df = df[['Entity', 'ad_creative_bodies', 'languages', 'Affiliation']]\n",
    "df['English'] = \"\"\n",
    "df['Spanish'] = \"\"\n",
    "df['languages'] = df.apply(lambda row: 'en' if row['languages']==\"['en']\" else row['languages'], axis=1)\n",
    "df['languages'] = df.apply(lambda row: 'es' if row['languages']==\"['es']\" else row['languages'], axis=1)\n",
    "df['ad_creative_bodies'] = df['ad_creative_bodies'].apply(lambda x: str(x).replace('\"', '').replace(\"['\", '').replace(\"']\", '').replace(\"[\", '').replace(\"]\", ''))\n",
    "\n",
    "df['English'] = df.apply(lambda row: row['ad_creative_bodies'] if row['languages']=='en' else '', axis=1)\n",
    "df['Spanish'] = df.apply(lambda row: row['ad_creative_bodies'] if row['languages']=='es' else '', axis=1)\n",
    "del df['ad_creative_bodies']\n",
    "df = df[df['languages']!=\"['en', 'es']\"]\n",
    "\n",
    "df_analysis = pd.concat([df, df_debate]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baselines for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a standard spanish, english training dataset\n",
    "    # baseline for the sentiment model\n",
    "# calculate the delta of translation which is separate from the sentimate delta, w/ the same dataset?\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translations and Sentiment calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/torch_base/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier:\n",
    "    def __init__(self, model_name):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    def classify(self, text):\n",
    "        # Tokenize the input text and obtain model outputs\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs).logits\n",
    "            probs = softmax(outputs, dim=1)\n",
    "            rating = torch.dot(probs.view(-1), torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])).item()\n",
    "            # label = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "        return np.round(rating, 4)\n",
    "\n",
    "classifier = SentimentClassifier(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the sentiment difference between ads and their translations\n",
    "    # add party column to dataset and combine debate data into one dataset\n",
    "    # translate the dataset\n",
    "    # calculate the sentiment delta between the original and translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "class T5Translator:\n",
    "    def __init__(self, model_name: str = \"t5-small\"):\n",
    "        \"\"\"\n",
    "        Initialize the T5 Translator with the specified model.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the T5 model. Default is \"t5-small\".\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        \n",
    "    def translate(self, text: str, source_language: str, target_language: str) -> str:\n",
    "        \"\"\"\n",
    "        Translate text from the source language to the target language.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The input text to be translated.\n",
    "            source_language (str): The source language code (e.g., \"en\" for English).\n",
    "            target_language (str): The target language code (e.g., \"es\" for Spanish).\n",
    "            \n",
    "        Returns:\n",
    "            str: The translated text.\n",
    "        \"\"\"\n",
    "        # Prepare the prompt text for the T5 model. For example: \"translate English to Spanish: Hello\"\n",
    "        prompt = f\"translate {source_language} to {target_language}: {text}\"\n",
    "        \n",
    "        # Tokenize the prompt text\n",
    "        inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(self.device)\n",
    "        \n",
    "        # Generate the translated text\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(inputs)\n",
    "        \n",
    "        # Decode the translated text\n",
    "        translated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        if \"en to es: \" in translated_text:\n",
    "            translated_text = translated_text.replace(\"en to es:\", \"\").strip()\n",
    "        elif \"es to en: \" in translated_text:\n",
    "            translated_text = translated_text.replace(\"es to en:\", \"\").strip()\n",
    "        \n",
    "        return translated_text\n",
    "\n",
    "# Instantiate the T5Translator\n",
    "translator = T5Translator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/torch_base/lib/python3.10/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def getTranslation(row, translator):\n",
    "    if row['Spanish'] == '':\n",
    "        row['Spanish'] = translator.translate(row['English'], \"en\", \"es\")\n",
    "    elif row['English'] == '':\n",
    "        row['English'] = translator.translate(row['Spanish'], \"es\", \"en\")\n",
    "    return row\n",
    "\n",
    "df_analysis = df_analysis.apply(lambda row: getTranslation(row, translator), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Gente Organizada and the ACLU have filed a law...\n",
       "1                              en to es en to es en to es\n",
       "2                         We need universal vote-by-mail.\n",
       "3       Katie ist AZs erster Demokrat, der seit 2 Jahr...\n",
       "4                    AZ ist ein Schlachtfeldstaat, der im\n",
       "                              ...                        \n",
       "1088                     Y también han dicho lo opuesto. \n",
       "1089                                            Importa –\n",
       "1090                       También han dicho lo opuesto. \n",
       "1091    Ninguna, ninguna persona seria ha dicho lo opu...\n",
       "1092                                  También han dicho –\n",
       "Name: Spanish, Length: 1093, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis.Spanish\n",
    "# TODO: fix translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['EN_sentiment'] = df_analysis.apply(lambda row: classifier.classify(row['English']), axis=1)\n",
    "df_analysis['ES_sentiment'] = df_analysis.apply(lambda row: classifier.classify(row['Spanish']), axis=1)\n",
    "df_analysis['sentimentDiff_EN-ES'] = df_analysis['EN_sentiment'] - df_analysis['ES_sentiment']\n",
    "df_analysis['sentimentDiff_ES-EN'] = df_analysis['ES_sentiment'] - df_analysis['EN_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.to_csv('analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def tTest(groupA, groupB, alternative='two-sided'):\n",
    "    equal_var = False\n",
    "    # If the ratio of the larger sample variance to the smaller sample variance is less than 4. This means we can assume that the population variances are equal.\n",
    "    if max(np.var(groupA), np.var(groupB)) / min(np.var(groupA), np.var(groupB)) < 4:\n",
    "        equal_var = True\n",
    "\n",
    "    #perform two sample t-test with equal variances\n",
    "    return stats.ttest_ind(a=groupA, b=groupB, equal_var=equal_var, alternative=alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ES-EN Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=0.8315368034778755, pvalue=0.40933246313341876, df=54.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupA = df_analysis[(df_analysis['languages'] == 'es') & (df_analysis['Affiliation'] == 'R')]['sentimentDiff_EN-ES']\n",
    "groupB = df_analysis[(df_analysis['languages']=='es') & (df_analysis['Affiliation']=='D')]['sentimentDiff_EN-ES']\n",
    "tTest(groupA, groupB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EN-ES Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-2.4012451426854597, pvalue=0.016514952347529612, df=1035.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupA = df_analysis[(df_analysis['languages']=='en') & (df_analysis['Affiliation']=='R')]['sentimentDiff_ES-EN']\n",
    "groupB = df_analysis[(df_analysis['languages']=='en') & (df_analysis['Affiliation']=='D')]['sentimentDiff_ES-EN']\n",
    "tTest(groupA, groupB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
